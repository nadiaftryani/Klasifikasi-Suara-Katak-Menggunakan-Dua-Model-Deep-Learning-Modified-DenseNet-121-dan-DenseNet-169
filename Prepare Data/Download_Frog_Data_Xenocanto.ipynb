{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download data dari Xeno Canto"
      ],
      "metadata": {
        "id": "xrihDFJh1NqD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI_zOvSbxeqD",
        "outputId": "3b176115-ad0b-435d-f99b-966b8ea5ef20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set path untuk menyimpan data di Google Drive\n",
        "corepath = \"/content/drive/MyDrive/TUBES DL/Persiapan Data/\"\n",
        "if not os.path.exists(corepath):\n",
        "    os.makedirs(corepath)\n",
        "\n",
        "def download_file(url, filename):\n",
        "    \"\"\"\n",
        "    Download a file from a URL and save it locally.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with urllib.request.urlopen(url) as response, open(filename, 'wb') as outfile:\n",
        "            outfile.write(response.read())\n",
        "        print(f\"Downloaded: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {url}: {e}\")\n",
        "\n",
        "def save_frog_data(frog_species_list):\n",
        "    \"\"\"\n",
        "    Fetch metadata and audio files for a list of frog species from Xeno-canto.\n",
        "    \"\"\"\n",
        "    for frog in frog_species_list:\n",
        "        count = 0\n",
        "        samples_limit = 10  # Maximum number of samples per species\n",
        "        path = os.path.join(corepath, frog.replace(':', '').replace(' ', '_'))\n",
        "\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Creating directory {path} for {frog}...\")\n",
        "            os.makedirs(path)\n",
        "\n",
        "        page = 1\n",
        "        while count < samples_limit:\n",
        "            url = f'https://www.xeno-canto.org/api/2/recordings?query={frog.replace(\" \", \"%20\")}&page={page}'\n",
        "            print(f\"Fetching data from: {url}\")\n",
        "\n",
        "            try:\n",
        "                response = urllib.request.urlopen(url)\n",
        "                jsondata = json.loads(response.read().decode('utf-8'))\n",
        "                recordings = jsondata.get('recordings', [])\n",
        "\n",
        "                for record in recordings:\n",
        "                    if count >= samples_limit:\n",
        "                        break\n",
        "\n",
        "                    # Save metadata\n",
        "                    metadata_filename = os.path.join(path, f\"sample_{count + 1}_metadata.json\")\n",
        "                    with open(metadata_filename, 'w') as outfile:\n",
        "                        json.dump(record, outfile)\n",
        "                    print(f\"Saved metadata: {metadata_filename}\")\n",
        "\n",
        "                    # Download audio file\n",
        "                    audio_url = record['file']  # Direct URL to audio file\n",
        "                    audio_filename = os.path.join(path, f\"sample_{count + 1}.mp3\")\n",
        "                    download_file(audio_url, audio_filename)\n",
        "\n",
        "                    count += 1\n",
        "\n",
        "                if not recordings or count >= samples_limit:\n",
        "                    break\n",
        "\n",
        "                page += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching data for {frog}: {e}\")\n",
        "                break\n",
        "\n",
        "        print(f\"Collected {count} samples for {frog}.\")\n",
        "\n",
        "# List of frog species to fetch\n",
        "frog_species_list = [\n",
        "    \"Boana cinerascens\",\n",
        "    \"Pepper Treefrog\",\n",
        "    \"Pool Frog\",\n",
        "    \"South American White-lipped Grassfrog\",\n",
        "    \"Dendropsophus minutus\",\n",
        "    \"Rana temporaria\",\n",
        "    \"Rhinella marina\",\n",
        "    \"Leptodactylus fuscus\",\n",
        "    \"Scinax ruber\"\n",
        "]\n",
        "\n",
        "save_frog_data(frog_species_list)"
      ],
      "metadata": {
        "id": "093VcteXyd6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save to CSV"
      ],
      "metadata": {
        "id": "4HLSchSg1Rc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGp-bFM41CsL",
        "outputId": "df855d78-6589-450f-b3f0-e9273bd3a480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import ffmpeg\n",
        "\n",
        "# Menghubungkan Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path untuk menyimpan data\n",
        "corepath = \"/content/drive/My Drive/Download_Frog_Data/\"\n",
        "os.chdir(corepath)  # Ganti direktori kerja ke folder data\n",
        "\n",
        "# Menggabungkan metadata CSV\n",
        "extension = 'json'  # Semua file metadata disimpan dalam format JSON\n",
        "all_metadata_files = [i for i in glob.glob(f'**/*.json', recursive=True)]\n",
        "\n",
        "# mengubah JSON metadata menjadi DataFrame\n",
        "def load_metadata(file):\n",
        "    try:\n",
        "        data = pd.read_json(file, typ='series')  # Baca JSON sebagai Series\n",
        "        return pd.DataFrame([data])  # Ubah Series menjadi DataFrame\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Menggabungkan semua metadata ke dalam satu DataFrame\n",
        "all_metadata = pd.concat([load_metadata(f) for f in all_metadata_files], ignore_index=True)\n",
        "\n",
        "# Simpan ke file CSV gabungan\n",
        "combined_csv_path = \"frog_metadata.csv\"\n",
        "all_metadata.to_csv(combined_csv_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"==========Done Combine Metadata to CSV: {combined_csv_path}==========\")"
      ],
      "metadata": {
        "id": "iX0xVN4S0yvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/frog_metadata.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ple4L56c1Xwf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}